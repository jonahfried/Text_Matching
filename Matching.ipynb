{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "blogPath = \"./blogs/\"\n",
    "pathList = os.listdir(path=blogPath)\n",
    "blogSampleSize = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1000331', 'female', '37', 'indUnk', 'Leo', 'xml']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathList[0].split(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOccupation(lst):\n",
    "    rtrn = []\n",
    "    for person in lst:\n",
    "        rtrn.append(person.split(\".\")[3])\n",
    "    return rtrn\n",
    "\n",
    "occupations = getOccupation(pathList)[:blogSampleSize]\n",
    "occupationDict = {}\n",
    "occupationCounter = 0\n",
    "for occ in occupations:\n",
    "    if occ not in occupationDict:\n",
    "        occupationDict[occ] = str(occupationCounter)\n",
    "        occupationCounter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "blogs = []\n",
    "for ind in range(blogSampleSize):\n",
    "    file = open(blogPath+pathList[ind], \"rb\")\n",
    "    posts = []\n",
    "    for line in file:\n",
    "        text = line.decode(\"utf-8\", errors=\"ignore\")\n",
    "        text = text.strip()\n",
    "        if text != \"\" and text[0] != \"<\":\n",
    "            posts.append(text)\n",
    "    blogs.append(\" \".join(posts))\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits up a string into a list of words.\n",
    "# str -> [str]\n",
    "def getWords(str):\n",
    "    words = []\n",
    "    \n",
    "    str = str+\".\"\n",
    "    lastInd = 0\n",
    "    for ind in range(len(str)):\n",
    "        if not (str[ind].isalpha()):\n",
    "            if lastInd == ind:\n",
    "                lastInd += 1\n",
    "                continue\n",
    "            else:\n",
    "                words.append(str[lastInd:ind].lower())\n",
    "                lastInd = ind+1\n",
    "    \n",
    "    return words\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts = []\n",
    "allWordsSeen = {}\n",
    "for blog in blogs:\n",
    "    newDict = {}\n",
    "    dicts.append(newDict)\n",
    "    wordList = getWords(blog)\n",
    "    for word in wordList:\n",
    "#         ADD TO THIS PERSON'S DICT\n",
    "        if word not in newDict:\n",
    "            newDict[word] = 1\n",
    "        else:\n",
    "            newDict[word] += 1\n",
    "#         ADD TO ALL WORDS SEEN\n",
    "        if word not in allWordsSeen:\n",
    "            allWordsSeen[word] = 1\n",
    "        else:\n",
    "            allWordsSeen[word] += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalPeople = len(dicts)\n",
    "wordsToRemove = []\n",
    "for word in allWordsSeen:\n",
    "    count = allWordsSeen[word]\n",
    "    \n",
    "    if ((count / totalPeople) > .50) or ((count / totalPeople) < .01):\n",
    "#         print(word)\n",
    "#         del allWordsSeen[word]\n",
    "        wordsToRemove.append(word)\n",
    "        for person in dicts:\n",
    "            if word in person:\n",
    "                del person[word]\n",
    "    else:\n",
    "        for person in dicts:\n",
    "            if word not in person:\n",
    "                person[word] = 0\n",
    "\n",
    "for word in wordsToRemove:\n",
    "    del allWordsSeen[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictOfDicts = {}\n",
    "for ind in range(blogSampleSize):\n",
    "    dictOfDicts[pathList[ind]] = dicts[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tdm = pd.DataFrame(dictOfDicts, dtype=float)\n",
    "# tdm = tdm.transpose()\n",
    "# tdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def termFrequency(person):\n",
    "    return .5 + (.5*person/person.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (This step scales really badly)\n",
    "\n",
    "IDF_Dict = {}\n",
    "for word in allWordsSeen:\n",
    "    personCount = 0\n",
    "    for person in tdm:\n",
    "        if tdm[person][word] > 0:\n",
    "            personCount += 1\n",
    "    if personCount > 0:\n",
    "        IDF_Dict[word] = math.log(blogSampleSize / personCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDF_Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for person in tdm:\n",
    "    tdm[person] = termFrequency(tdm[person])\n",
    "    for i in range(len(person)):\n",
    "        tdm[person][i] = tdm[person][i] * IDF_Dict[tdm[person].keys()[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosDist = sum(ser1*ser2)/(sqrt(sum(ser1^2)) * sqrt(sum(ser2^2)))\n",
    "def cosDist(ser1, ser2):\n",
    "    numerator = ser1.dot(ser2)\n",
    "    ser1Denominator = 0\n",
    "    for val in ser1:\n",
    "        ser1Denominator += math.pow(val, 2)\n",
    "    ser1Denominator = math.sqrt(ser1Denominator)\n",
    "    ser2Denominator = 0\n",
    "    for val in ser2:\n",
    "        ser2Denominator += math.pow(val, 2)\n",
    "    ser2Denominator = math.sqrt(ser2Denominator)\n",
    "    return 1 - numerator/(ser1Denominator*ser2Denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = tdm.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# (This step scales really badly)\n",
    "\n",
    "similarityDict = {}\n",
    "for person in tdm:\n",
    "    similarityDict[person] = {}\n",
    "    \n",
    "for ind in range(len(keys)):\n",
    "    for i in range(len(keys)):\n",
    "        dist = cosDist(tdm[keys[ind]], tdm[keys[i]])\n",
    "        similarityDict[keys[ind]][keys[i]] = ((dist < .0003) and (dist > .000000001))\n",
    "#         if ((dist < .00007) and (dist > .000000001)):\n",
    "#             print(dist)\n",
    "#             print(i)\n",
    "#             print(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarityFrame = pd.DataFrame(similarityDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# similarityFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarityFrame.to_json(path_or_buf=\"./similarity.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarityFrame = similarityFrame.transpose()\n",
    "# similarityFrame.to_csv(path_or_buf=\"./similarity.csv\", index_label=\"person\", na_rep=\"undefined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"writeTest.json\", \"w\")\n",
    "file.write(\"{\")\n",
    "file.write('\"nodes\":[')\n",
    "for i in range(len(tdm.keys())-1):\n",
    "    file.write('{\"id\": \"'+tdm.keys()[i]+'\", \"group\":'+ occupationDict[occupations[i]] +'},')\n",
    "file.write('{\"id\": \"'+tdm.keys()[len(tdm.keys())-1]+'\", \"group\": 1'+ occupationDict[occupations[i]] +'}')\n",
    "file.write(\"],\")\n",
    "\n",
    "file.write('\"links\":[')\n",
    "for person in similarityFrame:\n",
    "    for relation in similarityFrame[person].keys():\n",
    "        if similarityFrame[person][relation]:\n",
    "            file.write('{\"source\": \"'+person+'\", \"target\": \"'+relation+'\", \"value\": 1}, \\n')\n",
    "file.write(\"]\")\n",
    "file.write(\"}\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
