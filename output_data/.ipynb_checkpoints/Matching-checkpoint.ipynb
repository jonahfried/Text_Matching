{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "blogPath = \"./blogs/\"\n",
    "pathList = os.listdir(path=blogPath)\n",
    "blogSampleSize = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1000331', 'female', '37', 'indUnk', 'Leo', 'xml']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathList[0].split(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOccupation(lst):\n",
    "    rtrn = []\n",
    "    for person in lst:\n",
    "        rtrn.append(person.split(\".\")[3])\n",
    "    return rtrn\n",
    "\n",
    "occupations = getOccupation(pathList)[:blogSampleSize]\n",
    "occupationDict = {}\n",
    "occupationCounter = 0\n",
    "for occ in occupations:\n",
    "    if occ not in occupationDict:\n",
    "        occupationDict[occ] = str(occupationCounter)\n",
    "        occupationCounter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "blogs = []\n",
    "for ind in range(blogSampleSize):\n",
    "    file = open(blogPath+pathList[ind], \"rb\")\n",
    "    posts = []\n",
    "    for line in file:\n",
    "        text = line.decode(\"utf-8\", errors=\"ignore\")\n",
    "        text = text.strip()\n",
    "        if text != \"\" and text[0] != \"<\":\n",
    "            posts.append(text)\n",
    "    blogs.append(\" \".join(posts))\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits up a string into a list of words.\n",
    "# str -> [str]\n",
    "def getWords(str):\n",
    "    words = []\n",
    "    \n",
    "    str = str+\".\"\n",
    "    lastInd = 0\n",
    "    for ind in range(len(str)):\n",
    "        if not (str[ind].isalpha()):\n",
    "            if lastInd == ind:\n",
    "                lastInd += 1\n",
    "                continue\n",
    "            else:\n",
    "                words.append(str[lastInd:ind].lower())\n",
    "                lastInd = ind+1\n",
    "    \n",
    "    return words\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts = []\n",
    "allWordsSeen = {}\n",
    "for blog in blogs:\n",
    "    newDict = {}\n",
    "    dicts.append(newDict)\n",
    "    wordList = getWords(blog)\n",
    "    for word in wordList:\n",
    "#         ADD TO THIS PERSON'S DICT\n",
    "        if word not in newDict:\n",
    "            newDict[word] = 1\n",
    "        else:\n",
    "            newDict[word] += 1\n",
    "#         ADD TO ALL WORDS SEEN\n",
    "        if word not in allWordsSeen:\n",
    "            allWordsSeen[word] = 1\n",
    "        else:\n",
    "            allWordsSeen[word] += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalPeople = len(dicts)\n",
    "testWordList = [word for word in allWordsSeen if ((allWordsSeen[word] > .50) or (allWordsSeen < .01))]\n",
    "wordsToRemove = []\n",
    "for word in allWordsSeen:\n",
    "    count = allWordsSeen[word]\n",
    "    \n",
    "    if ((count / totalPeople) > .50) or ((count / totalPeople) < .01):\n",
    "#         print(word)\n",
    "#         del allWordsSeen[word]\n",
    "        wordsToRemove.append(word)\n",
    "        for person in dicts:\n",
    "            if word in person:\n",
    "                del person[word]\n",
    "    else:\n",
    "        for person in dicts:\n",
    "            if word not in person:\n",
    "                person[word] = 0\n",
    "\n",
    "for word in wordsToRemove:\n",
    "    del allWordsSeen[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testWord' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4a7c8c149399>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestWord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'testWord' is not defined"
     ]
    }
   ],
   "source": [
    "print(testWordList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictOfDicts = {}\n",
    "for ind in range(blogSampleSize):\n",
    "    dictOfDicts[pathList[ind]] = dicts[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tdm = pd.DataFrame(dictOfDicts, dtype=float)\n",
    "# tdm = tdm.transpose()\n",
    "# tdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def termFrequency(person):\n",
    "    return .5 + (.5*person/person.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (This step scales really badly)\n",
    "\n",
    "IDF_Dict = {}\n",
    "for word in allWordsSeen:\n",
    "    personCount = 0\n",
    "    for person in tdm:\n",
    "        if tdm[person][word] > 0:\n",
    "            personCount += 1\n",
    "    if personCount > 0:\n",
    "        IDF_Dict[word] = math.log(blogSampleSize / personCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDF_Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for person in tdm:\n",
    "    tdm[person] = termFrequency(tdm[person])\n",
    "    for i in range(len(person)):\n",
    "        tdm[person][i] = tdm[person][i] * IDF_Dict[tdm[person].keys()[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tdm['1000331.female.37.indUnk.Leo.xml']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosDist = sum(ser1*ser2)/(sqrt(sum(ser1^2)) * sqrt(sum(ser2^2)))\n",
    "# def cosDist(ser1, ser2):\n",
    "#     numerator = ser1.dot(ser2)\n",
    "#     ser1Denominator = 0\n",
    "#     for val in ser1:\n",
    "#         ser1Denominator += math.pow(val, 2)\n",
    "#     ser1Denominator = math.sqrt(ser1Denominator)\n",
    "#     ser2Denominator = 0\n",
    "#     for val in ser2:\n",
    "#         ser2Denominator += math.pow(val, 2)\n",
    "#     ser2Denominator = math.sqrt(ser2Denominator)\n",
    "#     return 1 - numerator/(ser1Denominator*ser2Denominator)\n",
    "\n",
    "def cosDist(ser1, ser2):\n",
    "    numerator = ser1.dot(ser2)\n",
    "    # ser1Denominator = itertools.accumulate(ser1, )\n",
    "    # for val in ser1:\n",
    "    #     ser1Denominator += math.pow(val, 2)\n",
    "    ser1Denominator = math.sqrt(sum(map((lambda x: x**2), ser1)))\n",
    "    ser2Denominator = math.sqrt(sum(map((lambda x: x**2), ser2)))\n",
    "    # ser2Denominator = 0\n",
    "    # for val in ser2:\n",
    "    #     ser2Denominator += math.pow(val, 2)\n",
    "    # ser2Denominator = math.sqrt(ser2Denominator)\n",
    "    return 1 - numerator/(ser1Denominator*ser2Denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosDist(tdm['1000331.female.37.indUnk.Leo.xml'], tdm['1008329.female.16.Student.Pisces.xml'])\n",
    "pt1 = math.sqrt(sum(map((lambda x: x**2), tdm['1000331.female.37.indUnk.Leo.xml'])))\n",
    "pt2 = math.sqrt(sum(map((lambda x: x**2), tdm['1011153.female.27.Technology.Virgo.xml'])))\n",
    "pt1*pt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDict = {person:{relation:cosDist(tdm[person], tdm[relation]) for relation in tdm} for person in tdm}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # (This step scales really badly)\n",
    "\n",
    "# similarityDict = {}\n",
    "# for person in tdm:\n",
    "#     similarityDict[person] = {}\n",
    "    \n",
    "# for ind in range(len(keys)):\n",
    "#     for i in range(len(keys)):\n",
    "#         dist = cosDist(tdm[keys[ind]], tdm[keys[i]])\n",
    "#         similarityDict[keys[ind]][keys[i]] = ((dist < .0003) and (dist > .000000001))\n",
    "# #         if ((dist < .00007) and (dist > .000000001)):\n",
    "# #             print(dist)\n",
    "# #             print(i)\n",
    "# #             print(ind)\n",
    "\n",
    "simalarityDict = {person:{relation:cosDist(tdm[person], tdm[relation]) for relation in tdm} for person in tdm}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarityFrame = pd.DataFrame(similarityDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "person = similarityFrame[\"1004904.male.23.Arts.Capricorn.xml\"]\n",
    "for p in person.keys():\n",
    "    print(person[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarityFrame.to_json(path_or_buf=\"./similarity.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarityFrame = similarityFrame.transpose()\n",
    "# similarityFrame.to_csv(path_or_buf=\"./similarity.csv\", index_label=\"person\", na_rep=\"undefined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"writeTest.json\", \"w\")\n",
    "file.write(\"{\")\n",
    "file.write('\"nodes\":[')\n",
    "for i in range(len(tdm.keys())-1):\n",
    "    file.write('{\"id\": \"'+tdm.keys()[i]+'\", \"group\":'+ occupationDict[occupations[i]] +'},')\n",
    "file.write('{\"id\": \"'+tdm.keys()[len(tdm.keys())-1]+'\", \"group\": 1'+ occupationDict[occupations[i]] +'}')\n",
    "file.write(\"],\")\n",
    "\n",
    "file.write('\"links\":[')\n",
    "for person in similarityFrame:\n",
    "    for relation in similarityFrame[person].keys():\n",
    "        if similarityFrame[person][relation]:\n",
    "            file.write('{\"source\": \"'+person+'\", \"target\": \"'+relation+'\", \"value\": 1}, \\n')\n",
    "file.write(\"]\")\n",
    "file.write(\"}\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
